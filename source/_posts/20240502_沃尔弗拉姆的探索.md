---
title:沃尔夫拉姆的探索
date: 2024-05-02 18:20:31
description:
categories: 读书笔记
tags: []
toc:
feature:
---

# 序

如果不知道神人Stephen Wolfram，这是个很正常的事情。毕竟如果我不从事复杂领域的学习和研究，我也大概率不知道这个人，然而当我知道他竟然提出了实现图灵机的第二种形式，元胞自动机，而且还专门推出了产品Mathematica并为导演诺兰做了许多虚拟现实的特效后，我也开始使用Mathematica了。

<!-- more -->

# 沃尔夫拉姆的探索--《这就是CHatGPT》

其实，沃尔夫拉姆是个神童，13岁自己写了几本物理方面的书，15岁发表了高能物理论文，20岁在加州理工直接拿了博士学位，导师是传奇的费曼。没多久，他的兴趣就从物理转移到了复杂领域，一起参与了圣塔菲研究所的工作。为了完成自己的构想，专门开发了数学软件，还成了企业家，书中的很多可视化的图像就是用Mathematica来生成的，毕竟不是每个人都能很好地把抽象数学语言变成一种直观的可视化具象。不过，神人竟然能为ChatGPT写一本科普的小书，而且用的都是下里巴人的语言，甚至把构建神经网络的参数形象地比喻成了“旋转的按钮”，我想这种叙事风格怕是从导师费曼那里学过来的。

## 智能的本质

另一个很重要的原因，我认为沃尔夫拉姆是觉得自己的工作和ChatGPT有异曲同工之妙：希望能找到人类大脑的本质。一个长期不被看好的神经网络技术，从明斯克创立人工智能的理论开始就不看好神经网络，辛顿也长期在学术界的边缘坚持着自己的努力，直到有一天这个技术真的爆发了，接着提出的Transformer的模型在学术界又被Google的Bert模型吊打，事实上现在证明有时候的学术主流，并不是真正的主流，至少Google的大模型远远落后于ChatGPT，甚至还拼不过Meta的llama。然而，Transformer的成功，某个程度揭示了：在ChatGPT这个神经网络中，能以某种方式捕捉到人类大脑在生成语言时所做事情的本质。

## 简单和复杂

在复杂领域中，我们认同一个观点，即使基础规则很简单，计算过程也可以极大地放大系统的表面复杂性，这就是混沌和涌现本质。CHatGPT的训练过程，表明ChatGPT已经通过某种方式“隐含地发现”了在一大堆语料中关于语言（和思维）规律，包括语法、表述以及语义推断。多年来，沃尔夫拉姆尝试开发一种精确的符号表示，以尽可能广泛地谈论世界上的事物，以及我们关心的抽象事物（例如，我们有城市、分子、图像和神经网络的符号表示，还有关于如何计算这些事物的内置知识）。他也成功了，至少在书的第二部分，他展现了在一些很具体的可以计算的模型中，CHatGPT不如Wolfram的地方，并表示CHatGPT也承认了那一点，并不断地和Wolfram系统调整学习相关的内容。



书中原话是这么表达的：

>​      ChatGPT在“类人的部分”表现出色，因为其中没有精确的“正确答案”。但当它被“赶鸭子上架”、需要提供精确的内容时，往往会失败。这些例子要表达的重点是，有一种很好的方法可以解决该问题—将ChatGPT连接到Wolfram|Alpha以利用其全部的计算知识“超能力”。
>
>​	在Wolfram|Alpha内部，一切都被转换为计算语言，转换为精确的Wolfram语言代码。这些代码在某种程度上必须是“完美”的，才能可靠地使用。关键是，ChatGPT无须生成这些代码。它可以生成自己常用的自然语言，然后由Wolfram|Alpha利用其自然语言理解能力转换为精确的Wolfram语言。
>
>​	在许多方面，可以说ChatGPT从未“真正理解”过事物，它只“知道如何产生有用的东西”。但是Wolfram|Alpha则完全不同。因为一旦Wolfram|Alpha将某些东西转换为Wolfram语言，我们就拥有了它们完整、精确、形式化的表示，可以用来可靠地计算事物。

# 结语

有时候，我总在想，是不是太多的人纠结于算力，纠结于模型，而忘记了为什么要做这个东西。人体是个很优秀的生物体，然而它并不是完美的，人工智能应如是。

不过我觉得，想了解CHatGPT和底层理论技术的人，不妨从阅读这本书开始，因为书中几乎没有任何的学术词汇。

